{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import model_evaluation_utils as meu\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#from sklearn.preprocessing import get_feature_names\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import h2o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- Due to limited time, we only explored briefly the Random forest Algorithm using H20 framework.\n",
    "- We recommend to go directly to the next Notebook 4Models_Comparison_ROC_Final to see the modelling comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\mstre\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\mstre\\AppData\\Local\\Temp\\tmp17d_c6bx\n",
      "  JVM stdout: C:\\Users\\mstre\\AppData\\Local\\Temp\\tmp17d_c6bx\\h2o_mstre_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\mstre\\AppData\\Local\\Temp\\tmp17d_c6bx\\h2o_mstre_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>7 days, 19 hours and 46 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_mstre_it1s05</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.539 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster timezone:       Europe/Berlin\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.2\n",
       "H2O cluster version age:    7 days, 19 hours and 46 minutes\n",
       "H2O cluster name:           H2O_from_python_mstre_it1s05\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.539 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.remove_all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(h2o)\n",
    "#help(H2OGradientBoostingEstimator)\n",
    "#help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_df = h2o.import_file(os.path.realpath(\"../data/covtype.full.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mstre\\\\Dropbox\\\\0Big_data\\\\Other_proj\\\\05 Data Science Interview'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "stroke_pred1  = h2o.import_file('stroke_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and testing\n",
    "train, test = stroke_pred1.split_frame(ratios=[0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare predictors and response columns\n",
    "stroke_pred1_X = stroke_pred1.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "stroke_pred1_y = stroke_pred1.col_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2ORandomForestEstimator in module h2o.estimators.random_forest:\n",
      "\n",
      "class H2ORandomForestEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Distributed Random Forest\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2ORandomForestEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  binomial_double_trees\n",
      " |      For binary classification: Build 2x as many trees (one per class) - can lead to higher accuracy.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  build_tree_one_node\n",
      " |      Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibrate_model\n",
      " |      Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates\n",
      " |      of class probabilities.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibration_frame\n",
      " |      Calibration frame for Platt Scaling\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  categorical_encoding\n",
      " |      Encoding scheme for categorical features\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
      " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  check_constant_response\n",
      " |      Check if response column is constant. If enabled, then an exception is thrown if the response column is a\n",
      " |      constant value.If disabled, then model will train regardless of the response column being a constant value or\n",
      " |      not.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  checkpoint\n",
      " |      Model checkpoint to resume training with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  col_sample_rate_change_per_level\n",
      " |      Relative change of the column sampling rate for every level (must be > 0.0 and <= 2.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  col_sample_rate_per_tree\n",
      " |      Column sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  distribution\n",
      " |      [Deprecated] Distribution function\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``, ``\"gamma\"``,\n",
      " |      ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  export_checkpoints_dir\n",
      " |      Automatically export generated models to this directory.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  histogram_type\n",
      " |      What type of histogram to use for finding optimal split points\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"uniform_adaptive\"``, ``\"random\"``, ``\"quantiles_global\"``, ``\"round_robin\"``  (default:\n",
      " |      ``\"auto\"``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_models\n",
      " |      Whether to keep the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_depth\n",
      " |      Maximum tree depth.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  min_rows\n",
      " |      Fewest allowed (weighted) observations in a leaf.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  min_split_improvement\n",
      " |      Minimum relative improvement in squared error reduction for a split to happen\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-05``).\n",
      " |  \n",
      " |  mtries\n",
      " |      Number of variables randomly sampled as candidates at each split. If set to -1, defaults to sqrt{p} for\n",
      " |      classification and p/3 for regression (where p is the # of predictors\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  nbins\n",
      " |      For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  nbins_cats\n",
      " |      For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher\n",
      " |      values can lead to more overfitting.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nbins_top_level\n",
      " |      For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease\n",
      " |      by factor of two per level\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  ntrees\n",
      " |      Number of trees.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``50``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      [Deprecated] Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  r2_stopping\n",
      " |      r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and\n",
      " |      stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or\n",
      " |      exceeds this\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  sample_rate\n",
      " |      Row sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.6320000291``).\n",
      " |  \n",
      " |  sample_rate_per_class\n",
      " |      A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  score_tree_interval\n",
      " |      Score the model after every so many trees. Disabled if set to 0.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  stopping_metric\n",
      " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression). Note that custom\n",
      " |      and custom_increasing can only be used in GBM and DRF with the Python client.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
      " |      ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``, ``\"custom\"``, ``\"custom_increasing\"``\n",
      " |      (default: ``\"auto\"``).\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
      " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'drf'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |      1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      h2oModelD = H2OXGBoostEstimator(**h2oParamsD) # parameters specified as a dict()\n",
      " |      h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |      h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |      2. Derive the DMatrix from H2OFrame:\n",
      " |      nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |      3. Derive the parameters for native XGBoost:\n",
      " |      nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |      4. Train your native XGBoost model and generate a prediction:\n",
      " |      nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |      nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1].\n",
      " |      \n",
      " |      5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, save_to_file=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :param save_to_file Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |      into cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_contributions(self, test_data)\n",
      " |      Predict feature contributions - SHAP values on an H2O Model (only GBM and XGBoost models).\n",
      " |      \n",
      " |      Returned H2OFrame has shape (#rows, #features + 1) - there is a feature contribution column for each input\n",
      " |      feature, the last column is the model bias (same value for each row). The sum of the feature contributions\n",
      " |      and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum \n",
      " |      of the predictions of the individual trees before before the inverse link function is applied to get the actual\n",
      " |      prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction. \n",
      " |      \n",
      " |      Note: Multinomial classification models are currently not supported.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to calculate contributions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame made of feature contributions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |      of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  end_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  run_time\n",
      " |      Model training time in milliseconds\n",
      " |  \n",
      " |  start_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2ORandomForestEstimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Random Forest\n",
    "# We build our first model with the following parameters\n",
    "# \n",
    "# **model_id:** Not required, but allows us to easily find our model in the [Flow](http://localhost:54321/) interface  \n",
    "# **ntrees:** Maximum number of trees used by the random forest. Default value is 50. We can afford to increase this, as our early-stopping criterion will decide when the random forest is sufficiently accurate.  \n",
    "# **stopping_rounds:** Stopping criterion described above. Stops fitting new trees when 2-tree rolling average is within 0.001 (default) of the two prior rolling averages. Can be thought of as a convergence setting.  \n",
    "# **score_each_teration:** predict against training and validation for each tree. Default will skip several.  \n",
    "# **seed:** set the randomization seed so we can reproduce results\n",
    "# \n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"stroke_pred1_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "seed=1000000, balance_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v1.train(stroke_pred1_X, stroke_pred1_y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  stroke_pred1_v1\n",
      "\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.018650176807220795\n",
      "RMSE: 0.13656565017317054\n",
      "MAE: 0.036285282688349935\n",
      "RMSLE: 0.09837706806040206\n",
      "Mean Residual Deviance: 0.018650176807220795\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:20</td>\n",
       "<td> 0.031 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:21</td>\n",
       "<td> 0.478 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1903752</td>\n",
       "<td>0.0365291</td>\n",
       "<td>0.0362427</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:21</td>\n",
       "<td> 0.619 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1848412</td>\n",
       "<td>0.0369232</td>\n",
       "<td>0.0341663</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:21</td>\n",
       "<td> 0.720 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1762910</td>\n",
       "<td>0.0357785</td>\n",
       "<td>0.0310785</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:21</td>\n",
       "<td> 0.820 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1720388</td>\n",
       "<td>0.0358217</td>\n",
       "<td>0.0295973</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:24</td>\n",
       "<td> 3.900 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1367216</td>\n",
       "<td>0.0362073</td>\n",
       "<td>0.0186928</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:24</td>\n",
       "<td> 3.954 sec</td>\n",
       "<td>51.0</td>\n",
       "<td>0.1366393</td>\n",
       "<td>0.0361999</td>\n",
       "<td>0.0186703</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:24</td>\n",
       "<td> 4.001 sec</td>\n",
       "<td>52.0</td>\n",
       "<td>0.1365945</td>\n",
       "<td>0.0362075</td>\n",
       "<td>0.0186580</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:24</td>\n",
       "<td> 4.038 sec</td>\n",
       "<td>53.0</td>\n",
       "<td>0.1365685</td>\n",
       "<td>0.0362266</td>\n",
       "<td>0.0186510</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 21:46:24</td>\n",
       "<td> 4.101 sec</td>\n",
       "<td>54.0</td>\n",
       "<td>0.1365657</td>\n",
       "<td>0.0362853</td>\n",
       "<td>0.0186502</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse        training_mae          training_deviance\n",
       "---  -------------------  ----------  -----------------  -------------------  --------------------  --------------------\n",
       "     2019-04-24 21:46:20  0.031 sec   0.0                nan                  nan                   nan\n",
       "     2019-04-24 21:46:21  0.478 sec   1.0                0.19037518446535429  0.03652913900698208   0.03624271086021767\n",
       "     2019-04-24 21:46:21  0.619 sec   2.0                0.18484124469288715  0.036923152748410085  0.03416628573961578\n",
       "     2019-04-24 21:46:21  0.720 sec   3.0                0.17629099153305952  0.03577846787607175   0.031078513695709267\n",
       "     2019-04-24 21:46:21  0.820 sec   4.0                0.17203879434419686  0.035821674158206446  0.02959734675940486\n",
       "---  ---                  ---         ---                ---                  ---                   ---\n",
       "     2019-04-24 21:46:24  3.900 sec   50.0               0.13672160694873153  0.03620733765235407   0.018692797806643433\n",
       "     2019-04-24 21:46:24  3.954 sec   51.0               0.13663929121272558  0.03619990128846496   0.018670295903116026\n",
       "     2019-04-24 21:46:24  4.001 sec   52.0               0.136594456987396    0.036207518017619254  0.018658045679681576\n",
       "     2019-04-24 21:46:24  4.038 sec   53.0               0.1365684910552222   0.03622657373334547   0.018650952749100308\n",
       "     2019-04-24 21:46:24  4.101 sec   54.0               0.13656565017317054  0.036285282688349935  0.018650176807220795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Avg_Glucose</td>\n",
       "<td>5496.8974609</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2751168</td></tr>\n",
       "<tr><td>Age</td>\n",
       "<td>4816.8481445</td>\n",
       "<td>0.8762849</td>\n",
       "<td>0.2410807</td></tr>\n",
       "<tr><td>BMI</td>\n",
       "<td>4641.4965820</td>\n",
       "<td>0.8443848</td>\n",
       "<td>0.2323044</td></tr>\n",
       "<tr><td>Smoking_Status</td>\n",
       "<td>1520.3039551</td>\n",
       "<td>0.2765749</td>\n",
       "<td>0.0760904</td></tr>\n",
       "<tr><td>Type_Of_Work</td>\n",
       "<td>936.0564575</td>\n",
       "<td>0.1702881</td>\n",
       "<td>0.0468491</td></tr>\n",
       "<tr><td>Residence</td>\n",
       "<td>791.9248657</td>\n",
       "<td>0.1440676</td>\n",
       "<td>0.0396354</td></tr>\n",
       "<tr><td>Gender</td>\n",
       "<td>709.8948364</td>\n",
       "<td>0.1291446</td>\n",
       "<td>0.0355299</td></tr>\n",
       "<tr><td>Hypertension</td>\n",
       "<td>396.7693787</td>\n",
       "<td>0.0721806</td>\n",
       "<td>0.0198581</td></tr>\n",
       "<tr><td>Heart_Disease</td>\n",
       "<td>360.8428955</td>\n",
       "<td>0.0656448</td>\n",
       "<td>0.0180600</td></tr>\n",
       "<tr><td>Ever_Married</td>\n",
       "<td>309.1984253</td>\n",
       "<td>0.0562496</td>\n",
       "<td>0.0154752</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Avg_Glucose     5496.9                 1                    0.275117\n",
       "Age             4816.85                0.876285             0.241081\n",
       "BMI             4641.5                 0.844385             0.232304\n",
       "Smoking_Status  1520.3                 0.276575             0.0760904\n",
       "Type_Of_Work    936.056                0.170288             0.0468491\n",
       "Residence       791.925                0.144068             0.0396354\n",
       "Gender          709.895                0.129145             0.0355299\n",
       "Hypertension    396.769                0.0721806            0.0198581\n",
       "Heart_Disease   360.843                0.0656448            0.01806\n",
       "Ever_Married    309.198                0.0562496            0.0154752"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_mae</th>\n",
       "      <th>training_deviance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:20</td>\n",
       "      <td>0.031 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>0.478 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190375</td>\n",
       "      <td>0.036529</td>\n",
       "      <td>0.036243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>0.619 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.184841</td>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.034166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>0.720 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.176291</td>\n",
       "      <td>0.035778</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>0.820 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.172039</td>\n",
       "      <td>0.035822</td>\n",
       "      <td>0.029597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>0.909 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.167849</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>0.028173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>1.030 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.164065</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.026917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>1.131 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.161448</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>1.211 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.024780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>1.284 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.154890</td>\n",
       "      <td>0.036024</td>\n",
       "      <td>0.023991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:21</td>\n",
       "      <td>1.347 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.152428</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>0.023234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.448 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.022876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.532 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.149581</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.022375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.626 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.148742</td>\n",
       "      <td>0.036185</td>\n",
       "      <td>0.022124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.695 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.148156</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>0.021950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.764 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.147241</td>\n",
       "      <td>0.036583</td>\n",
       "      <td>0.021680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.849 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.146502</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>0.021463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.927 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.145553</td>\n",
       "      <td>0.036527</td>\n",
       "      <td>0.021186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>1.996 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.144811</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>2.065 sec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.143958</td>\n",
       "      <td>0.036423</td>\n",
       "      <td>0.020724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>2.134 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.143404</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.020565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>2.212 sec</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.142783</td>\n",
       "      <td>0.036598</td>\n",
       "      <td>0.020387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>2.281 sec</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.142274</td>\n",
       "      <td>0.036537</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:22</td>\n",
       "      <td>2.350 sec</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.141765</td>\n",
       "      <td>0.036484</td>\n",
       "      <td>0.020097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.412 sec</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.141325</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.019973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.466 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.019813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.535 sec</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.140492</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.019738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.613 sec</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>0.019620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.666 sec</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.139741</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>0.019527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.729 sec</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.139555</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.019476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.782 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.139295</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.019403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.835 sec</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.036330</td>\n",
       "      <td>0.019325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.898 sec</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.138949</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.019307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.951 sec</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.138802</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.019266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>2.998 sec</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.138625</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>0.019217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.067 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.138450</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>0.019168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.136 sec</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.138303</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>0.019128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.183 sec</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.138135</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>0.019081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.236 sec</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.137972</td>\n",
       "      <td>0.036285</td>\n",
       "      <td>0.019036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.299 sec</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.137805</td>\n",
       "      <td>0.036267</td>\n",
       "      <td>0.018990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:23</td>\n",
       "      <td>3.352 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.137697</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.018960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.430 sec</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>0.018917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.468 sec</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.137409</td>\n",
       "      <td>0.036335</td>\n",
       "      <td>0.018881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.531 sec</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.137248</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>0.018837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.568 sec</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.137141</td>\n",
       "      <td>0.036321</td>\n",
       "      <td>0.018808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.631 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.137059</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.018785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.669 sec</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.136973</td>\n",
       "      <td>0.036264</td>\n",
       "      <td>0.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.731 sec</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.136952</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>0.018756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.784 sec</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.136880</td>\n",
       "      <td>0.036217</td>\n",
       "      <td>0.018736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.853 sec</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.136833</td>\n",
       "      <td>0.036236</td>\n",
       "      <td>0.018723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.900 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.136722</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.018693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>3.954 sec</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.136639</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.018670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>4.001 sec</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.136594</td>\n",
       "      <td>0.036208</td>\n",
       "      <td>0.018658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>4.038 sec</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.136568</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>0.018651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 21:46:24</td>\n",
       "      <td>4.101 sec</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.136566</td>\n",
       "      <td>0.036285</td>\n",
       "      <td>0.018650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2019-04-24 21:46:20   0.031 sec              0.0            NaN   \n",
       "1     2019-04-24 21:46:21   0.478 sec              1.0       0.190375   \n",
       "2     2019-04-24 21:46:21   0.619 sec              2.0       0.184841   \n",
       "3     2019-04-24 21:46:21   0.720 sec              3.0       0.176291   \n",
       "4     2019-04-24 21:46:21   0.820 sec              4.0       0.172039   \n",
       "5     2019-04-24 21:46:21   0.909 sec              5.0       0.167849   \n",
       "6     2019-04-24 21:46:21   1.030 sec              6.0       0.164065   \n",
       "7     2019-04-24 21:46:21   1.131 sec              7.0       0.161448   \n",
       "8     2019-04-24 21:46:21   1.211 sec              8.0       0.157417   \n",
       "9     2019-04-24 21:46:21   1.284 sec              9.0       0.154890   \n",
       "10    2019-04-24 21:46:21   1.347 sec             10.0       0.152428   \n",
       "11    2019-04-24 21:46:22   1.448 sec             11.0       0.151247   \n",
       "12    2019-04-24 21:46:22   1.532 sec             12.0       0.149581   \n",
       "13    2019-04-24 21:46:22   1.626 sec             13.0       0.148742   \n",
       "14    2019-04-24 21:46:22   1.695 sec             14.0       0.148156   \n",
       "15    2019-04-24 21:46:22   1.764 sec             15.0       0.147241   \n",
       "16    2019-04-24 21:46:22   1.849 sec             16.0       0.146502   \n",
       "17    2019-04-24 21:46:22   1.927 sec             17.0       0.145553   \n",
       "18    2019-04-24 21:46:22   1.996 sec             18.0       0.144811   \n",
       "19    2019-04-24 21:46:22   2.065 sec             19.0       0.143958   \n",
       "20    2019-04-24 21:46:22   2.134 sec             20.0       0.143404   \n",
       "21    2019-04-24 21:46:22   2.212 sec             21.0       0.142783   \n",
       "22    2019-04-24 21:46:22   2.281 sec             22.0       0.142274   \n",
       "23    2019-04-24 21:46:22   2.350 sec             23.0       0.141765   \n",
       "24    2019-04-24 21:46:23   2.412 sec             24.0       0.141325   \n",
       "25    2019-04-24 21:46:23   2.466 sec             25.0       0.140759   \n",
       "26    2019-04-24 21:46:23   2.535 sec             26.0       0.140492   \n",
       "27    2019-04-24 21:46:23   2.613 sec             27.0       0.140072   \n",
       "28    2019-04-24 21:46:23   2.666 sec             28.0       0.139741   \n",
       "29    2019-04-24 21:46:23   2.729 sec             29.0       0.139555   \n",
       "30    2019-04-24 21:46:23   2.782 sec             30.0       0.139295   \n",
       "31    2019-04-24 21:46:23   2.835 sec             31.0       0.139013   \n",
       "32    2019-04-24 21:46:23   2.898 sec             32.0       0.138949   \n",
       "33    2019-04-24 21:46:23   2.951 sec             33.0       0.138802   \n",
       "34    2019-04-24 21:46:23   2.998 sec             34.0       0.138625   \n",
       "35    2019-04-24 21:46:23   3.067 sec             35.0       0.138450   \n",
       "36    2019-04-24 21:46:23   3.136 sec             36.0       0.138303   \n",
       "37    2019-04-24 21:46:23   3.183 sec             37.0       0.138135   \n",
       "38    2019-04-24 21:46:23   3.236 sec             38.0       0.137972   \n",
       "39    2019-04-24 21:46:23   3.299 sec             39.0       0.137805   \n",
       "40    2019-04-24 21:46:23   3.352 sec             40.0       0.137697   \n",
       "41    2019-04-24 21:46:24   3.430 sec             41.0       0.137540   \n",
       "42    2019-04-24 21:46:24   3.468 sec             42.0       0.137409   \n",
       "43    2019-04-24 21:46:24   3.531 sec             43.0       0.137248   \n",
       "44    2019-04-24 21:46:24   3.568 sec             44.0       0.137141   \n",
       "45    2019-04-24 21:46:24   3.631 sec             45.0       0.137059   \n",
       "46    2019-04-24 21:46:24   3.669 sec             46.0       0.136973   \n",
       "47    2019-04-24 21:46:24   3.731 sec             47.0       0.136952   \n",
       "48    2019-04-24 21:46:24   3.784 sec             48.0       0.136880   \n",
       "49    2019-04-24 21:46:24   3.853 sec             49.0       0.136833   \n",
       "50    2019-04-24 21:46:24   3.900 sec             50.0       0.136722   \n",
       "51    2019-04-24 21:46:24   3.954 sec             51.0       0.136639   \n",
       "52    2019-04-24 21:46:24   4.001 sec             52.0       0.136594   \n",
       "53    2019-04-24 21:46:24   4.038 sec             53.0       0.136568   \n",
       "54    2019-04-24 21:46:24   4.101 sec             54.0       0.136566   \n",
       "\n",
       "    training_mae  training_deviance  \n",
       "0            NaN                NaN  \n",
       "1       0.036529           0.036243  \n",
       "2       0.036923           0.034166  \n",
       "3       0.035778           0.031079  \n",
       "4       0.035822           0.029597  \n",
       "5       0.035945           0.028173  \n",
       "6       0.036066           0.026917  \n",
       "7       0.036320           0.026065  \n",
       "8       0.036026           0.024780  \n",
       "9       0.036024           0.023991  \n",
       "10      0.035734           0.023234  \n",
       "11      0.036100           0.022876  \n",
       "12      0.035996           0.022375  \n",
       "13      0.036185           0.022124  \n",
       "14      0.036480           0.021950  \n",
       "15      0.036583           0.021680  \n",
       "16      0.036573           0.021463  \n",
       "17      0.036527           0.021186  \n",
       "18      0.036505           0.020970  \n",
       "19      0.036423           0.020724  \n",
       "20      0.036495           0.020565  \n",
       "21      0.036598           0.020387  \n",
       "22      0.036537           0.020242  \n",
       "23      0.036484           0.020097  \n",
       "24      0.036563           0.019973  \n",
       "25      0.036476           0.019813  \n",
       "26      0.036443           0.019738  \n",
       "27      0.036396           0.019620  \n",
       "28      0.036387           0.019527  \n",
       "29      0.036392           0.019476  \n",
       "30      0.036401           0.019403  \n",
       "31      0.036330           0.019325  \n",
       "32      0.036391           0.019307  \n",
       "33      0.036409           0.019266  \n",
       "34      0.036343           0.019217  \n",
       "35      0.036296           0.019168  \n",
       "36      0.036325           0.019128  \n",
       "37      0.036296           0.019081  \n",
       "38      0.036285           0.019036  \n",
       "39      0.036267           0.018990  \n",
       "40      0.036304           0.018960  \n",
       "41      0.036314           0.018917  \n",
       "42      0.036335           0.018881  \n",
       "43      0.036314           0.018837  \n",
       "44      0.036321           0.018808  \n",
       "45      0.036281           0.018785  \n",
       "46      0.036264           0.018761  \n",
       "47      0.036272           0.018756  \n",
       "48      0.036217           0.018736  \n",
       "49      0.036236           0.018723  \n",
       "50      0.036207           0.018693  \n",
       "51      0.036200           0.018670  \n",
       "52      0.036208           0.018658  \n",
       "53      0.036227           0.018651  \n",
       "54      0.036285           0.018650  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1.score_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v2 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v2\",\n",
    "    ntrees=200,\n",
    "    max_depth=30,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01,\n",
    "    score_each_iteration=True,\n",
    "    seed=3000000, balance_classes=True)\n",
    "\n",
    "rf_v2.train(stroke_pred1_X, stroke_pred1_y, training_frame=train, validation_frame = test)\n",
    "\n",
    "# note: main parameter to tweak = depth of the tree and number of predictors to use \n",
    "#(mtries, default for classification = 1/3 of the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  rf_covType_v2\n",
      "\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.022474508364131063\n",
      "RMSE: 0.1499150037992564\n",
      "MAE: 0.036768816269752765\n",
      "RMSLE: 0.10991445707464521\n",
      "Mean Residual Deviance: 0.022474508364131063\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.019677642093128667\n",
      "RMSE: 0.14027701911977125\n",
      "MAE: 0.036563713496832746\n",
      "RMSLE: 0.10094241705423208\n",
      "Mean Residual Deviance: 0.019677642093128667\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_mae</b></td>\n",
       "<td><b>validation_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:44</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:44</td>\n",
       "<td> 0.100 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1912017</td>\n",
       "<td>0.0368453</td>\n",
       "<td>0.0365581</td>\n",
       "<td>0.1941269</td>\n",
       "<td>0.0381302</td>\n",
       "<td>0.0376852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:44</td>\n",
       "<td> 0.200 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1868085</td>\n",
       "<td>0.0372812</td>\n",
       "<td>0.0348974</td>\n",
       "<td>0.1626255</td>\n",
       "<td>0.0353510</td>\n",
       "<td>0.0264471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:44</td>\n",
       "<td> 0.316 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.1815069</td>\n",
       "<td>0.0372177</td>\n",
       "<td>0.0329447</td>\n",
       "<td>0.1541533</td>\n",
       "<td>0.0359163</td>\n",
       "<td>0.0237632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.416 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.1751439</td>\n",
       "<td>0.0368606</td>\n",
       "<td>0.0306754</td>\n",
       "<td>0.1500360</td>\n",
       "<td>0.0363647</td>\n",
       "<td>0.0225108</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.485 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.1704071</td>\n",
       "<td>0.0369021</td>\n",
       "<td>0.0290386</td>\n",
       "<td>0.1484990</td>\n",
       "<td>0.0369555</td>\n",
       "<td>0.0220519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.579 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.1656534</td>\n",
       "<td>0.0364162</td>\n",
       "<td>0.0274410</td>\n",
       "<td>0.1457871</td>\n",
       "<td>0.0365328</td>\n",
       "<td>0.0212539</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.632 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.1622874</td>\n",
       "<td>0.0365314</td>\n",
       "<td>0.0263372</td>\n",
       "<td>0.1445964</td>\n",
       "<td>0.0366293</td>\n",
       "<td>0.0209081</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.686 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1592135</td>\n",
       "<td>0.0365307</td>\n",
       "<td>0.0253489</td>\n",
       "<td>0.1432574</td>\n",
       "<td>0.0367725</td>\n",
       "<td>0.0205227</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.748 sec</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1565473</td>\n",
       "<td>0.0365446</td>\n",
       "<td>0.0245071</td>\n",
       "<td>0.1423509</td>\n",
       "<td>0.0367016</td>\n",
       "<td>0.0202638</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.802 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.1544550</td>\n",
       "<td>0.0366398</td>\n",
       "<td>0.0238563</td>\n",
       "<td>0.1412119</td>\n",
       "<td>0.0364429</td>\n",
       "<td>0.0199408</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.864 sec</td>\n",
       "<td>11.0</td>\n",
       "<td>0.1528996</td>\n",
       "<td>0.0366508</td>\n",
       "<td>0.0233783</td>\n",
       "<td>0.1406422</td>\n",
       "<td>0.0363630</td>\n",
       "<td>0.0197802</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 0.933 sec</td>\n",
       "<td>12.0</td>\n",
       "<td>0.1515323</td>\n",
       "<td>0.0367623</td>\n",
       "<td>0.0229620</td>\n",
       "<td>0.1404124</td>\n",
       "<td>0.0364931</td>\n",
       "<td>0.0197156</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-24 22:13:45</td>\n",
       "<td> 1.002 sec</td>\n",
       "<td>13.0</td>\n",
       "<td>0.1499150</td>\n",
       "<td>0.0367688</td>\n",
       "<td>0.0224745</td>\n",
       "<td>0.1402770</td>\n",
       "<td>0.0365637</td>\n",
       "<td>0.0196776</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_mae    training_deviance    validation_rmse    validation_mae    validation_deviance\n",
       "--  -------------------  ----------  -----------------  ---------------  --------------  -------------------  -----------------  ----------------  ---------------------\n",
       "    2019-04-24 22:13:44  0.000 sec   0                  nan              nan             nan                  nan                nan               nan\n",
       "    2019-04-24 22:13:44  0.100 sec   1                  0.191202         0.0368453       0.0365581            0.194127           0.0381302         0.0376852\n",
       "    2019-04-24 22:13:44  0.200 sec   2                  0.186809         0.0372812       0.0348974            0.162626           0.035351          0.0264471\n",
       "    2019-04-24 22:13:44  0.316 sec   3                  0.181507         0.0372177       0.0329447            0.154153           0.0359163         0.0237632\n",
       "    2019-04-24 22:13:45  0.416 sec   4                  0.175144         0.0368606       0.0306754            0.150036           0.0363647         0.0225108\n",
       "    2019-04-24 22:13:45  0.485 sec   5                  0.170407         0.0369021       0.0290386            0.148499           0.0369555         0.0220519\n",
       "    2019-04-24 22:13:45  0.579 sec   6                  0.165653         0.0364162       0.027441             0.145787           0.0365328         0.0212539\n",
       "    2019-04-24 22:13:45  0.632 sec   7                  0.162287         0.0365314       0.0263372            0.144596           0.0366293         0.0209081\n",
       "    2019-04-24 22:13:45  0.686 sec   8                  0.159213         0.0365307       0.0253489            0.143257           0.0367725         0.0205227\n",
       "    2019-04-24 22:13:45  0.748 sec   9                  0.156547         0.0365446       0.0245071            0.142351           0.0367016         0.0202638\n",
       "    2019-04-24 22:13:45  0.802 sec   10                 0.154455         0.0366398       0.0238563            0.141212           0.0364429         0.0199408\n",
       "    2019-04-24 22:13:45  0.864 sec   11                 0.1529           0.0366508       0.0233783            0.140642           0.036363          0.0197802\n",
       "    2019-04-24 22:13:45  0.933 sec   12                 0.151532         0.0367623       0.022962             0.140412           0.0364931         0.0197156\n",
       "    2019-04-24 22:13:45  1.002 sec   13                 0.149915         0.0367688       0.0224745            0.140277           0.0365637         0.0196776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Avg_Glucose</td>\n",
       "<td>1379.1060791</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2827049</td></tr>\n",
       "<tr><td>Age</td>\n",
       "<td>1186.0279541</td>\n",
       "<td>0.8599976</td>\n",
       "<td>0.2431256</td></tr>\n",
       "<tr><td>BMI</td>\n",
       "<td>1111.7725830</td>\n",
       "<td>0.8061545</td>\n",
       "<td>0.2279039</td></tr>\n",
       "<tr><td>Smoking_Status</td>\n",
       "<td>342.4597473</td>\n",
       "<td>0.2483201</td>\n",
       "<td>0.0702013</td></tr>\n",
       "<tr><td>Type_Of_Work</td>\n",
       "<td>223.2602234</td>\n",
       "<td>0.1618876</td>\n",
       "<td>0.0457664</td></tr>\n",
       "<tr><td>Gender</td>\n",
       "<td>198.1327972</td>\n",
       "<td>0.1436676</td>\n",
       "<td>0.0406155</td></tr>\n",
       "<tr><td>Residence</td>\n",
       "<td>192.1837311</td>\n",
       "<td>0.1393538</td>\n",
       "<td>0.0393960</td></tr>\n",
       "<tr><td>Hypertension</td>\n",
       "<td>99.1956558</td>\n",
       "<td>0.0719275</td>\n",
       "<td>0.0203343</td></tr>\n",
       "<tr><td>Heart_Disease</td>\n",
       "<td>74.2297821</td>\n",
       "<td>0.0538246</td>\n",
       "<td>0.0152165</td></tr>\n",
       "<tr><td>Ever_Married</td>\n",
       "<td>71.8838120</td>\n",
       "<td>0.0521235</td>\n",
       "<td>0.0147356</td></tr></table></div>"
      ],
      "text/plain": [
       "variable        relative_importance    scaled_importance    percentage\n",
       "--------------  ---------------------  -------------------  ------------\n",
       "Avg_Glucose     1379.11                1                    0.282705\n",
       "Age             1186.03                0.859998             0.243126\n",
       "BMI             1111.77                0.806155             0.227904\n",
       "Smoking_Status  342.46                 0.24832              0.0702013\n",
       "Type_Of_Work    223.26                 0.161888             0.0457664\n",
       "Gender          198.133                0.143668             0.0406155\n",
       "Residence       192.184                0.139354             0.039396\n",
       "Hypertension    99.1957                0.0719275            0.0203343\n",
       "Heart_Disease   74.2298                0.0538246            0.0152165\n",
       "Ever_Married    71.8838                0.0521235            0.0147356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_mae</th>\n",
       "      <th>training_deviance</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_mae</th>\n",
       "      <th>validation_deviance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:44</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:44</td>\n",
       "      <td>0.100 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191202</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>0.036558</td>\n",
       "      <td>0.194127</td>\n",
       "      <td>0.038130</td>\n",
       "      <td>0.037685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:44</td>\n",
       "      <td>0.200 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.186809</td>\n",
       "      <td>0.037281</td>\n",
       "      <td>0.034897</td>\n",
       "      <td>0.162626</td>\n",
       "      <td>0.035351</td>\n",
       "      <td>0.026447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:44</td>\n",
       "      <td>0.316 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.181507</td>\n",
       "      <td>0.037218</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.154153</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>0.023763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.416 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.175144</td>\n",
       "      <td>0.036861</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.150036</td>\n",
       "      <td>0.036365</td>\n",
       "      <td>0.022511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.485 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.170407</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.148499</td>\n",
       "      <td>0.036955</td>\n",
       "      <td>0.022052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.579 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.036416</td>\n",
       "      <td>0.027441</td>\n",
       "      <td>0.145787</td>\n",
       "      <td>0.036533</td>\n",
       "      <td>0.021254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.632 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.162287</td>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.144596</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>0.020908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.686 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.159213</td>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.143257</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.020523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.748 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.156547</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>0.142351</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.020264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.802 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.154455</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.023856</td>\n",
       "      <td>0.141212</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.019941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.864 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.140642</td>\n",
       "      <td>0.036363</td>\n",
       "      <td>0.019780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>0.933 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.151532</td>\n",
       "      <td>0.036762</td>\n",
       "      <td>0.022962</td>\n",
       "      <td>0.140412</td>\n",
       "      <td>0.036493</td>\n",
       "      <td>0.019716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2019-04-24 22:13:45</td>\n",
       "      <td>1.002 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.149915</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>0.140277</td>\n",
       "      <td>0.036564</td>\n",
       "      <td>0.019678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2019-04-24 22:13:44   0.000 sec              0.0            NaN   \n",
       "1     2019-04-24 22:13:44   0.100 sec              1.0       0.191202   \n",
       "2     2019-04-24 22:13:44   0.200 sec              2.0       0.186809   \n",
       "3     2019-04-24 22:13:44   0.316 sec              3.0       0.181507   \n",
       "4     2019-04-24 22:13:45   0.416 sec              4.0       0.175144   \n",
       "5     2019-04-24 22:13:45   0.485 sec              5.0       0.170407   \n",
       "6     2019-04-24 22:13:45   0.579 sec              6.0       0.165653   \n",
       "7     2019-04-24 22:13:45   0.632 sec              7.0       0.162287   \n",
       "8     2019-04-24 22:13:45   0.686 sec              8.0       0.159213   \n",
       "9     2019-04-24 22:13:45   0.748 sec              9.0       0.156547   \n",
       "10    2019-04-24 22:13:45   0.802 sec             10.0       0.154455   \n",
       "11    2019-04-24 22:13:45   0.864 sec             11.0       0.152900   \n",
       "12    2019-04-24 22:13:45   0.933 sec             12.0       0.151532   \n",
       "13    2019-04-24 22:13:45   1.002 sec             13.0       0.149915   \n",
       "\n",
       "    training_mae  training_deviance  validation_rmse  validation_mae  \\\n",
       "0            NaN                NaN              NaN             NaN   \n",
       "1       0.036845           0.036558         0.194127        0.038130   \n",
       "2       0.037281           0.034897         0.162626        0.035351   \n",
       "3       0.037218           0.032945         0.154153        0.035916   \n",
       "4       0.036861           0.030675         0.150036        0.036365   \n",
       "5       0.036902           0.029039         0.148499        0.036955   \n",
       "6       0.036416           0.027441         0.145787        0.036533   \n",
       "7       0.036531           0.026337         0.144596        0.036629   \n",
       "8       0.036531           0.025349         0.143257        0.036772   \n",
       "9       0.036545           0.024507         0.142351        0.036702   \n",
       "10      0.036640           0.023856         0.141212        0.036443   \n",
       "11      0.036651           0.023378         0.140642        0.036363   \n",
       "12      0.036762           0.022962         0.140412        0.036493   \n",
       "13      0.036769           0.022475         0.140277        0.036564   \n",
       "\n",
       "    validation_deviance  \n",
       "0                   NaN  \n",
       "1              0.037685  \n",
       "2              0.026447  \n",
       "3              0.023763  \n",
       "4              0.022511  \n",
       "5              0.022052  \n",
       "6              0.021254  \n",
       "7              0.020908  \n",
       "8              0.020523  \n",
       "9              0.020264  \n",
       "10             0.019941  \n",
       "11             0.019780  \n",
       "12             0.019716  \n",
       "13             0.019678  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v2.score_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avg_Glucose</td>\n",
       "      <td>1379.106079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>1186.027954</td>\n",
       "      <td>0.859998</td>\n",
       "      <td>0.243126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMI</td>\n",
       "      <td>1111.772583</td>\n",
       "      <td>0.806155</td>\n",
       "      <td>0.227904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smoking_Status</td>\n",
       "      <td>342.459747</td>\n",
       "      <td>0.248320</td>\n",
       "      <td>0.070201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type_Of_Work</td>\n",
       "      <td>223.260223</td>\n",
       "      <td>0.161888</td>\n",
       "      <td>0.045766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gender</td>\n",
       "      <td>198.132797</td>\n",
       "      <td>0.143668</td>\n",
       "      <td>0.040616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Residence</td>\n",
       "      <td>192.183731</td>\n",
       "      <td>0.139354</td>\n",
       "      <td>0.039396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hypertension</td>\n",
       "      <td>99.195656</td>\n",
       "      <td>0.071928</td>\n",
       "      <td>0.020334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Heart_Disease</td>\n",
       "      <td>74.229782</td>\n",
       "      <td>0.053825</td>\n",
       "      <td>0.015216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ever_Married</td>\n",
       "      <td>71.883812</td>\n",
       "      <td>0.052123</td>\n",
       "      <td>0.014736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable  relative_importance  scaled_importance  percentage\n",
       "0     Avg_Glucose          1379.106079           1.000000    0.282705\n",
       "1             Age          1186.027954           0.859998    0.243126\n",
       "2             BMI          1111.772583           0.806155    0.227904\n",
       "3  Smoking_Status           342.459747           0.248320    0.070201\n",
       "4    Type_Of_Work           223.260223           0.161888    0.045766\n",
       "5          Gender           198.132797           0.143668    0.040616\n",
       "6       Residence           192.183731           0.139354    0.039396\n",
       "7    Hypertension            99.195656           0.071928    0.020334\n",
       "8   Heart_Disease            74.229782           0.053825    0.015216\n",
       "9    Ever_Married            71.883812           0.052123    0.014736"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_v2.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_v2.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(H2ORandomForestEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perf = rf_v2.model_performance(train=True)  #train=True is the default, so it's not needed\n",
    "#perf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.019677642093128667\n",
      "RMSE: 0.14027701911977125\n",
      "MAE: 0.036563713496832746\n",
      "RMSLE: 0.10094241705423208\n",
      "Mean Residual Deviance: 0.019677642093128667\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = rf_v2.model_performance(test)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2ORegressionModelMetrics' has no attribute 'fprs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-fa4d3cb4eed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\utils\\backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\utils\\backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'H2ORegressionModelMetrics' has no attribute 'fprs'"
     ]
    }
   ],
   "source": [
    "fpr = out.fprs\n",
    "tpr = out.tprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2ORegressionModelMetrics' has no attribute 'fprs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-59846235aba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\utils\\backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\utils\\backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'H2ORegressionModelMetrics' has no attribute 'fprs'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='blue', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
